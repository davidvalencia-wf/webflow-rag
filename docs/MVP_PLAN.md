# Webflow RAG - MVP Implementation Plan

## Project Context

**Goal**: Ship a production-grade RAG web application answering Webflow questions, deployed on Webflow Cloud

**Content Sources**: Webflow University, Blog, API Docs, Forums (all official documentation)

**Deployment**: Webflow Cloud (Cloudflare Workers edge runtime)

**Timeline**: 3-week phased MVP

## Architecture

### Platform Stack
- **Runtime**: Webflow Cloud (Cloudflare Workers, Node.js 20+)
- **Framework**: Next.js 16 (App Router) with edge runtime
- **Storage**:
  - SQLite (Cloudflare D1) - metadata, chunks, queries, analytics
  - Key Value Store (Cloudflare KV) - caching, session data
  - Object Storage (Cloudflare R2) - source documents
- **Vectors**: Pinecone free tier (100k vectors, 1 index)
- **LLM**: OpenAI GPT-4o-mini (cost-effective for MVP)
- **Embeddings**: OpenAI text-embedding-3-small

### Data Flow

```
[User Query]
    ↓
[Next.js API Route: /api/ask]
    ↓
[Generate Embedding] → (Cache in KV)
    ↓
[Query Pinecone] → [Fetch Metadata from SQLite]
    ↓
[Assemble Context] → [Call OpenAI]
    ↓
[Stream Response] → [Log to SQLite]
    ↓
[Return Answer + Citations]
```

### ETL Pipeline (Manual)

```
[Source URLs/Files]
    ↓
[Download to etl/input/]
    ↓
[Parse & Clean] (Markdown, HTML, PDF)
    ↓
[Chunk Content] (512 tokens, 50 overlap)
    ↓
[Generate Embeddings] (OpenAI API)
    ↓
[Store in Pinecone + SQLite]
```

## Phase 1: Core Infrastructure (Week 1)

### Objectives
- ✅ Deploy working Next.js app to Webflow Cloud
- ✅ Configure SQLite database with schema
- ✅ Create health/version API endpoints
- ✅ Set up CI/CD with GitHub Actions
- ✅ Implement basic full-text search (no vectors)

### Deliverables

1. **Webflow Cloud Setup**
   - Install `webflow-cli`
   - Initialize project: `webflow cloud init`
   - Configure `wrangler.json` with SQLite binding
   - Deploy to Webflow Cloud

2. **Database Schema (SQLite)**
   ```sql
   -- documents: source materials
   CREATE TABLE documents (
     id TEXT PRIMARY KEY,
     uri TEXT NOT NULL UNIQUE,
     title TEXT,
     source_type TEXT,
     license TEXT,
     created_at TEXT DEFAULT (datetime('now')),
     updated_at TEXT DEFAULT (datetime('now'))
   );

   -- chunks: text segments with metadata
   CREATE TABLE chunks (
     id TEXT PRIMARY KEY,
     document_id TEXT NOT NULL,
     content TEXT NOT NULL,
     hash TEXT NOT NULL,
     token_count INTEGER,
     section TEXT,
     chunk_index INTEGER,
     created_at TEXT DEFAULT (datetime('now')),
     FOREIGN KEY (document_id) REFERENCES documents(id)
   );

   -- queries: user search history
   CREATE TABLE queries (
     id TEXT PRIMARY KEY,
     query_text TEXT NOT NULL,
     embedding_hash TEXT,
     user_ip TEXT,
     created_at TEXT DEFAULT (datetime('now'))
   );

   -- responses: LLM answers
   CREATE TABLE responses (
     id TEXT PRIMARY KEY,
     query_id TEXT NOT NULL,
     answer TEXT NOT NULL,
     sources TEXT, -- JSON array of source URIs
     model TEXT,
     latency_ms INTEGER,
     created_at TEXT DEFAULT (datetime('now')),
     FOREIGN KEY (query_id) REFERENCES queries(id)
   );

   -- feedback: user reactions
   CREATE TABLE feedback (
     id TEXT PRIMARY KEY,
     response_id TEXT NOT NULL,
     helpful INTEGER, -- 1=yes, 0=no, null=not answered
     issue_report TEXT,
     created_at TEXT DEFAULT (datetime('now')),
     FOREIGN KEY (response_id) REFERENCES responses(id)
   );

   -- indexes
   CREATE INDEX idx_chunks_document ON chunks(document_id);
   CREATE INDEX idx_chunks_hash ON chunks(hash);
   CREATE INDEX idx_queries_created ON queries(created_at DESC);
   CREATE INDEX idx_responses_query ON responses(query_id);

   -- full-text search (Phase 1 fallback)
   CREATE VIRTUAL TABLE chunks_fts USING fts5(content, content=chunks, content_rowid=id);
   ```

3. **API Endpoints**
   - `GET /api/health` - status check
   - `GET /api/version` - version info from package.json + GIT_SHA
   - `POST /api/search` - full-text search (Phase 1)
   - `POST /api/ask` - RAG query (Phase 2+)

4. **Environment Variables**
   ```bash
   # .env.example
   OPENAI_API_KEY=sk-...
   PINECONE_API_KEY=...
   PINECONE_INDEX_NAME=webflow-docs
   DATABASE_ID=...  # Auto-generated by Webflow Cloud
   KV_NAMESPACE_ID=...  # Auto-generated by Webflow Cloud
   R2_BUCKET_NAME=webflow-rag-assets
   ```

5. **GitHub Actions CI/CD**
   - Lint + TypeScript check
   - Build Next.js
   - Deploy to Webflow Cloud on push to `main`

### Success Criteria
- App deployed at `*.webflow.io`
- `/api/health` returns 200
- SQLite database created with schema
- Basic text search works

---

## Phase 2: RAG with Vectors (Week 2)

### Objectives
- ✅ Implement ETL pipeline for Webflow docs
- ✅ Set up Pinecone vector index
- ✅ Build RAG API endpoint with streaming
- ✅ Add caching layer (KV)

### Deliverables

1. **ETL Pipeline** (`etl/ingest.ts`)
   - Fetch Webflow University, API docs, blog posts
   - Parse HTML/Markdown
   - Chunk content (512 tokens, 50 overlap)
   - Generate embeddings (OpenAI)
   - Upload to Pinecone + SQLite
   - Validation: count checks, sample queries

2. **Pinecone Setup**
   - Create index (dimension: 1536 for text-embedding-3-small)
   - Configure metadata filters (source_type, section)
   - Batch upload script

3. **RAG API** (`/api/ask`)
   - Input validation (Zod)
   - Rate limiting (10 req/min per IP)
   - Pipeline:
     1. Generate query embedding (cache in KV)
     2. Search Pinecone (top_k=5)
     3. Fetch chunk metadata from SQLite
     4. Assemble context (max 4000 tokens)
     5. Call OpenAI with streaming
     6. Return citations
     7. Log query + response to SQLite

4. **Caching Strategy**
   - Cache embeddings (query hash → vector) in KV
   - Cache responses (query hash → answer) for 1 hour
   - Invalidation on new content

### Success Criteria
- 1000+ Webflow docs chunks indexed
- Semantic search returns relevant results
- Streaming answers with citations
- < 3s response time (p95)

---

## Phase 3: UI & Polish (Week 3)

### Objectives
- ✅ Build user-facing search UI
- ✅ Add feedback mechanisms
- ✅ Implement history/analytics
- ✅ Accessibility & i18n scaffolding

### Deliverables

1. **Search UI** (`apps/web/src/app/page.tsx`)
   - Search input with autocomplete
   - Streaming answer display
   - Cited sources with links
   - Copy answer button
   - Loading states

2. **Feedback System**
   - "Was this helpful?" thumbs up/down
   - "Report an issue" modal
   - Store in SQLite `feedback` table

3. **History View**
   - Local storage for queries
   - Server-side history (optional, authenticated)
   - Clear history function

4. **Accessibility**
   - WCAG 2.2 AA compliance
   - Keyboard navigation
   - Focus management
   - ARIA labels
   - Color contrast checks

5. **Analytics Dashboard** (`/api/admin/stats`)
   - Query volume
   - Top queries
   - Feedback scores
   - Response latency

### Success Criteria
- Functional UI, mobile-responsive
- Accessibility audit passes
- Analytics tracking all queries

---

## Cost Model (Monthly Estimates)

### 10,000 queries/month

| Service | Usage | Cost |
|---------|-------|------|
| OpenAI Embeddings | 10k queries × $0.00002/1k tokens | ~$1 |
| OpenAI GPT-4o-mini | 10k queries × 500 tokens × $0.15/1M | ~$0.75 |
| Pinecone Free Tier | 100k vectors, 1 index | $0 |
| Webflow Cloud | Included in plan | $0-$20 |
| **Total** | | **~$2-$22/month** |

### Cost Levers
1. **Caching aggressiveness** - cache hit rate 50% → saves ~$1/month
2. **Model choice** - GPT-4o-mini vs GPT-4o (10x cost difference)
3. **Top-k chunks** - 5 vs 10 chunks (affects context size)

---

## Threat Model & Security

### Data Types Stored
- User queries (potentially sensitive)
- IP addresses (for rate limiting)
- Feedback text (free-form user input)
- Source documents (public Webflow docs)

### Attack Surfaces
1. **Prompt Injection** - malicious queries trying to manipulate LLM
2. **Rate Limit Bypass** - distributed attacks
3. **SQL Injection** - unsafe query construction
4. **XSS** - rendering user feedback
5. **Data Exfiltration** - accessing full database

### Mitigations
- Input validation (Zod schemas, max lengths)
- Parameterized SQL queries (Drizzle ORM)
- Rate limiting by IP (Cloudflare Workers)
- Content Security Policy headers
- No PII collection (IP hashed for rate limit)
- Prompt injection detection (basic keyword filters)
- Output sanitization (HTML escaping)

---

## Technology Decisions

### Why Next.js over Astro?
- Better API route support for streaming
- Larger ecosystem for RAG use cases
- React Server Components for performance
- **Trade-off**: Astro is lighter, better for static content

### Why Pinecone over Embedded SQLite Vectors?
- Native vector similarity search (no manual cosine calculation)
- Scalable to 100k+ vectors
- Free tier sufficient for MVP
- **Trade-off**: External dependency, vendor lock-in

### Why OpenAI over Cloudflare Workers AI?
- Better quality embeddings and LLM responses
- Proven track record for RAG
- **Trade-off**: Higher cost, external API dependency

---

## Next Steps

**Ready to start Phase 1?** I'll:

1. Install and configure Webflow CLI
2. Set up SQLite database with migrations
3. Create health/version API endpoints
4. Deploy to Webflow Cloud
5. Set up GitHub Actions CI/CD

**Shall I proceed with Phase 1 implementation?**
